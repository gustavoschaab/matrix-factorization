{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF():\n",
    "    \n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "        \n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        \n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        \n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "        \n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            # Update biases\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "            \n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return mf.b + mf.b_u[:,np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: RuntimeWarning: overflow encountered in multiply\n",
      "/home/gustavo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: RuntimeWarning: invalid value encountered in subtract\n",
      "/home/gustavo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = nan\n",
      "Iteration: 20 ; error = nan\n",
      "\n",
      "P x Q:\n",
      "[[ 5.17854231  4.0330065   3.71977341 ...,  4.93560597  4.56053     4.44865273]\n",
      " [        nan         nan         nan ...,         nan         nan\n",
      "          nan]\n",
      " [ 4.69547585  3.22420166  4.59230425 ...,  4.65206148  3.9625595\n",
      "   4.98401853]\n",
      " ..., \n",
      " [ 5.31311936  3.8918895   3.88308889 ...,  4.77145253  4.38377315\n",
      "   4.79437315]\n",
      " [ 3.63786794  3.47418256  4.60362845 ...,  5.51511949  4.61224163\n",
      "   3.62621292]\n",
      " [        nan         nan         nan ...,         nan         nan\n",
      "          nan]]\n",
      "\n",
      "Global bias:\n",
      "4.10971428571\n",
      "\n",
      "User bias:\n",
      "[ 0.07509623         nan  0.02975796 ...,  0.02854405  0.42556058\n",
      "         nan]\n",
      "\n",
      "Item bias:\n",
      "[ 0.10746907 -0.97072846  0.3491994  -1.01549676  0.29118005 -0.77894788\n",
      "  0.35712179 -0.60727808 -0.19991397  0.30553757 -0.08449998  0.47042569\n",
      " -0.16629363  0.35997516 -0.20772117 -0.48640304  0.35118104  0.14380704\n",
      "  0.08438475  0.36686451  0.10597828  0.29637422  0.18995393  0.50741797\n",
      "  0.52576046  0.10019083 -0.83670858  0.08556846 -0.01890853 -0.55459362\n",
      "  0.49539945 -1.40852703  0.15677961  0.07367572  0.33859844  0.34542981\n",
      " -1.15974693 -0.9096571  -0.0616831  -0.85230296 -0.10881383 -0.15767391\n",
      "  0.42925315  0.59849713 -0.05377034 -0.14451353  0.68589451  0.51801238\n",
      " -0.61986621  0.3454658  -0.27350522 -1.01561476 -0.45608624 -0.62646266\n",
      " -0.00712869 -0.74537982 -0.33164895 -0.21874551 -1.88146346 -1.4502965\n",
      " -1.01339285  0.17938013 -0.83543271 -0.86112899 -0.49330777 -0.4537777\n",
      "  0.47256402  0.36113344 -0.4703609  -0.70227447 -0.1993624   0.13551649\n",
      "  0.38691398  0.20865408 -1.05681382  0.13337956 -0.035243    0.05699098\n",
      "  0.01306736  0.26841002  0.27420169  0.27943124  0.40165421 -1.01934706\n",
      " -1.72825046  0.57744287  0.40588578 -0.40718462  0.37581162 -1.33430528\n",
      "  0.49345257  0.39626305 -0.91858255  0.44114651  0.44069015  0.50457644\n",
      "  0.25683895  0.16011305  0.36715934  0.41552978  0.60926152 -1.37182361\n",
      "  0.28014713  0.40930487 -0.89116448 -0.57524327 -1.20890947 -0.28717901\n",
      " -0.80846595 -0.87785355  0.29462481 -0.65918042  0.13733826  0.42405897\n",
      "  0.07033549  0.30845349  0.10567144  0.20594255 -0.35079705  0.03786118\n",
      " -0.94726184  0.29804408 -0.07156642 -0.94494601  0.6783233  -0.37877471\n",
      "  0.35413111  0.52104759  0.33087904 -0.06469428 -0.22857648 -1.18373861\n",
      "  0.07489001  0.3347471   0.26705034  0.20772491  0.13816324 -1.09272848\n",
      " -0.26057442  0.47830315  0.04190351  0.36885434 -1.47873142  0.66519704\n",
      "  0.41676793 -1.1510446  -0.58780289  0.27172683  0.59071598  0.28734685\n",
      "  0.59201252 -0.2439613   0.31944578  0.37762504  0.46407792  0.34544126\n",
      "  0.55489966  0.35003304 -0.88978406  0.37605299  0.00871209 -0.07530819\n",
      "  0.28921414 -0.72837423 -0.47576762  0.37749255 -0.52660116 -0.7434734\n",
      " -0.32600062 -0.11056668  0.10056882 -0.80094383  0.52039311 -0.0464341\n",
      " -0.7467589   0.1282284   0.47898074  0.12727404 -0.06504293  0.17518052\n",
      " -0.63325964  0.39411677  0.27479039  0.23580055 -0.34568697  0.23690225\n",
      " -0.03123097 -0.05088994  0.06614089  0.47594894  0.52480878  0.37462303\n",
      "  0.39027755  0.33985407  0.44735641  0.45346316  0.31872387  0.38716968\n",
      "  0.38057532  0.29683859 -0.25733795  0.21792991  0.30241843 -0.51486528\n",
      "  0.27520143  0.2383013  -0.5711911  -0.25251001 -0.66329042  0.00827795\n",
      "  0.33551889  0.40320543  0.19947769 -0.5648099  -0.65064396  0.30652105\n",
      " -0.22958586 -1.27688653 -0.00722027  0.41802668  0.49150736 -0.07474837\n",
      "  0.54787743  0.36025852  0.22888414  0.52468255  0.420352    0.37998546\n",
      "  0.31526093  0.54892541 -0.69792698 -0.47001415 -0.62394301 -1.15841393\n",
      "  0.39652917 -0.77208968 -1.54801188 -1.12688785  0.40284599 -0.2177855\n",
      " -0.36670906 -0.22598781 -0.69021129  0.31797562         nan -0.17524673\n",
      "  0.58106421 -1.46355189         nan  0.19235036 -0.37217833 -0.29178994\n",
      "  0.05580588 -0.77161528 -0.16160249 -1.10973124 -0.52530334 -0.8363644\n",
      " -1.19316946         nan -0.80068202 -0.4504989          nan         nan\n",
      "         nan         nan -0.02789393 -0.05264324 -0.39197821  0.26955194\n",
      "  0.55014266  0.42972144 -0.05602991  0.69294757 -0.15100599 -0.46143762\n",
      "         nan  0.00347456         nan  0.37278093  0.45135046  0.32292655\n",
      "  0.28576392  0.24255189         nan -0.2701561   0.66142628  0.36038961\n",
      "  0.28017375 -0.8439115  -0.57193488  0.0671113  -0.84005844 -0.21902552\n",
      " -0.22287714 -0.75010443 -1.02339736 -0.69462297 -0.53292021 -0.24895866\n",
      " -0.07056759  0.77685584  0.13526883  0.11095791 -0.37870624  0.2628261\n",
      "         nan -0.16554464 -0.42538693 -0.41709034  0.1578137  -0.53333032\n",
      "  0.24583711  0.01315536  0.44757253 -0.8678594  -0.34905337 -0.57991196\n",
      " -0.0616267  -0.24122541 -1.12384994         nan         nan         nan\n",
      " -0.53803873  0.3822943  -0.29316129         nan -0.74724515  0.30959142\n",
      "  0.05654429  0.02976696  0.10322577 -0.36371259 -0.23915506  0.47097805\n",
      "  0.36947966  0.47244492 -1.23790683 -0.65136516 -0.99170942  0.28630191\n",
      " -0.10771327 -0.15889405 -0.83520145 -0.02821394  0.22467925  0.0150751\n",
      " -0.25287178  0.43419319  0.64949274  0.46164824  0.12206117 -0.02762043\n",
      "  0.41241361  0.22069683  0.31275848  0.68406385 -0.31960625  0.04155812\n",
      "  0.32618502  0.43259837  0.14085837 -0.31506269 -0.0593416   0.17100532\n",
      " -0.57645693 -0.821839   -0.0832509  -0.42487326 -0.19964897 -0.44389307\n",
      " -0.24843673 -1.02101259  0.32162657  0.42827561  0.16716782  0.22621837\n",
      "  0.05152881 -0.55105071 -0.9637728  -1.27017037  0.69628054 -0.68951461\n",
      "  0.42115883  0.68862697 -1.05841963 -0.1747558   0.66321646 -1.82682884\n",
      "  0.16153577 -0.34858134 -0.42886808 -0.57372604  0.20980383 -0.38312158\n",
      "  0.44754842  0.19020126 -0.07752535  0.29842728  0.67917398 -0.00510617\n",
      "  0.19812055  0.34820749  0.37079366  0.44958495 -0.43808732  0.1505123\n",
      " -0.50522297 -0.23124832 -0.05989042  0.14722971 -0.65526939 -0.08850967\n",
      " -0.50873399  0.32335785  0.49468822 -0.54718773  0.45920416 -0.05276147\n",
      " -0.23581332  0.36659208  0.35668511  0.40030608  0.00274034  0.23312551\n",
      "  0.1652696   0.37739959 -0.64840322  0.31796915 -1.30116695 -0.174528\n",
      "  0.25084853 -0.81616266 -0.9971649  -0.05865578  0.06726989 -0.97815623\n",
      " -0.8648197   0.36375352  0.12519904 -0.38707201  0.30867594  0.56617728\n",
      "  0.66031987 -0.10043123  0.16318979  0.32388577  0.57490209  0.59019331\n",
      " -1.02988378 -0.03854746 -0.18934601  0.67941198  0.13380966  0.60161917\n",
      "  0.17349551 -0.05085243 -1.23392799  0.31645074  0.12427938 -0.3126866\n",
      "  0.36325966  0.0696238  -0.17128817  0.45764933 -0.41052443  0.43814276\n",
      "  0.30944524  0.14882436  0.33454094 -0.76537196 -0.92635292 -0.75765972\n",
      "  0.08373183 -0.46392217 -0.63771853  0.37786316 -0.80930634  0.29356944\n",
      " -0.3299418   0.29472559 -0.45987227 -0.04487877 -0.1814103  -0.79625917\n",
      "  0.24329189  0.16989246 -0.22983762  0.50219756 -0.70871125 -0.20404797\n",
      "  0.21477164 -1.07153065  0.44154362  0.13168414 -0.06379008 -0.16011432\n",
      " -0.47521849 -0.07889727 -0.65085466  0.49349219  0.04393545  0.65128171\n",
      " -0.10770506  0.31948134]\n"
     ]
    }
   ],
   "source": [
    "ratings = [i.strip().split(\",\") for i in open('data/ratings.csv', 'r').readlines()]\n",
    "ratings_df = pd.DataFrame(ratings, columns = ['UserID', 'ItemID', 'Rating', 'Timestamp'], dtype = int)\n",
    "ratings_df[['Rating']] = ratings_df[['Rating']].apply(pd.to_numeric)\n",
    "R_df = ratings_df.pivot(index = 'UserID', columns ='ItemID', values = 'Rating').fillna(0)\n",
    "R = R_df.as_matrix()\n",
    "\n",
    "mf = MF(R, K=2, alpha=0.1, beta=0.01, iterations=20)\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(mf.full_matrix())\n",
    "print()\n",
    "print(\"Global bias:\")\n",
    "print(mf.b)\n",
    "print()\n",
    "print(\"User bias:\")\n",
    "print(mf.b_u)\n",
    "print()\n",
    "print(\"Item bias:\")\n",
    "print(mf.b_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  5.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.991801088787482"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.get_rating(0, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
